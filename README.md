# Machine-Learning
ML related projects
This notebook shows the basic idea for two-layers neural network and how to develop it from scratch as well as use Tensorflow and Pytorch.
The architecture of the neural network is connected by two forward pass, one rectified linear unit (ReLU) and one softmax function. 
Forward pass combine the input feature and the hidden laery by weights and bias. 
ReLU is general nonlinear part within modern neural network and softmax can generate multi-class probability for the prediction.
